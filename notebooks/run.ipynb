{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SingGlow Experiment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from common_definitions import *\r\n",
    "from pipeline import *\r\n",
    "import tensorflow as tf\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import librosa\r\n",
    "import librosa.display\r\n",
    "import soundfile as sf\r\n",
    "import IPython.display as ipd\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "import pickle\r\n",
    "from data_loarder import *\r\n",
    "\r\n",
    "os.chdir(r'D:\\PlayGround\\research\\SinGlow\\runs')\r\n",
    "BATCH_SIZE = 64"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "tfrecord_dir = r'D:\\PlayGround\\research\\SinGlow\\runs'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data_loader = SongDataLoader('real.tfrecords',tfrecord_dir=tfrecord_dir)\r\n",
    "data_loader.make(r'D:\\PlayGround\\research\\SongDatabase\\RealSinger\\vocal collection\\wav files')\r\n",
    "real_dataset = data_loader.load(sampling_num=200)\r\n",
    "del data_loader\r\n",
    "\r\n",
    "# data_loader = SongDataLoader('virtual.tfrecords',tfrecord_dir=tfrecord_dir)\r\n",
    "# data_loader.make(r'D:\\PlayGround\\research\\SongDatabase\\VirtualSinger')\r\n",
    "# virtual_dataset = data_loader.load()\r\n",
    "# del data_loader"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "6400it [02:06, 50.58it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Step ?. the brain\r\n",
    "brain = Brain(SQUEEZE_FACTOR, K_GLOW, L_GLOW, WINDOW_LENGTH, CHANNEL_SIZE, LEARNING_RATE)\r\n",
    "\r\n",
    "# load weight if available\r\n",
    "brain.model(tf.random.uniform((2, WINDOW_LENGTH, 1, CHANNEL_SIZE), 0.05, 1), training=True)\r\n",
    "CHECKPOINT_PATH = r'D:\\PlayGround\\research\\SinGlow\\checkpoints\\weights'\r\n",
    "print(brain.load_weights(CHECKPOINT_PATH))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\hobar\\anaconda3\\envs\\DeepLearningTF2\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:513: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "C:\\Users\\hobar\\anaconda3\\envs\\DeepLearningTF2\\lib\\site-packages\\keras\\engine\\base_layer.py:2215: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Weights loaded\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import pickle\r\n",
    "\r\n",
    "# real z\r\n",
    "\r\n",
    "real_z_path = r'D:\\PlayGround\\research\\SinGlow\\runs\\real_z.pickle'\r\n",
    "if os.path.exists(real_z_path):\r\n",
    "    with open(real_z_path,mode='rb') as f:\r\n",
    "        real_z = pickle.load(f)\r\n",
    "else:\r\n",
    "    real_z_results = []\r\n",
    "    for i in tqdm(real_dataset):\r\n",
    "        real_z_results.append(brain.forward(i).numpy()[0])\r\n",
    "    real_z = np.apply_along_axis(np.mean,0,np.array(real_z_results))\r\n",
    "    with open(real_z_path,mode='wb') as f:\r\n",
    "        pickle.dump(real_z, f)\r\n",
    "\r\n",
    "# # virtual z\r\n",
    "# if os.path.exists('virtual_z.pickle'):\r\n",
    "#     with open('virtual_z.pickle',mode='rb') as f:\r\n",
    "#         virtual_z = pickle.load(f)\r\n",
    "# else:\r\n",
    "#     virtual_z_results = []\r\n",
    "#     for i in tqdm(virtual_dataset):\r\n",
    "#         virtual_z_results.append(brain.forward(i).numpy()[0])\r\n",
    "\r\n",
    "#     virtual_z = np.apply_along_axis(np.mean,0,np.array(virtual_z_results))\r\n",
    "#     with open('virtual_z.pickle',mode='wb') as f:\r\n",
    "#         pickle.dump(virtual_z, f)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 200/200 [01:26<00:00,  2.32it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# # delta z\r\n",
    "# delta_z = real_z-virtual_z"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# figure, ax = plt.subplots(3)\r\n",
    "# figure.set_size_inches(12,9)\r\n",
    "# plt.subplots_adjust(hspace=1)\r\n",
    "\r\n",
    "# ax[0] = plt.plot(np.array(real_z))\r\n",
    "# # ax[1] = plt.plot(np.array(delta_z))\r\n",
    "# # ax[2] = plt.plot(np.array(virtual_z))\r\n",
    "\r\n",
    "# # librosa.display.waveplot(np.array(real_z), sr=SAMPLING_RATE, ax=ax[0])\r\n",
    "# # librosa.display.waveplot(np.array(delta_z), sr=SAMPLING_RATE, ax=ax[1])\r\n",
    "# # librosa.display.waveplot(np.array(virtual_z), sr=SAMPLING_RATE, ax=ax[2])\r\n",
    "\r\n",
    "# ax[0].set_title(\"real_z\")\r\n",
    "# # ax[1].set_title(\"delta_z\")\r\n",
    "# # ax[2].set_title(\"virtual_z\")\r\n",
    "# ax[0].set_ylim([-1,1])\r\n",
    "# # ax[1].set_ylim([-1,1])\r\n",
    "# # ax[2].set_ylim([-1,1])\r\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "os.chdir(r'D:\\PlayGround\\research\\SinGlow\\runs')\r\n",
    "\r\n",
    "virtual_file_dir = r'D:\\PlayGround\\research\\SongDatabase\\TestSongs'\r\n",
    "name = 'virtual_align_short'\r\n",
    "pickle_file  = f'result_{name}.pickle'\r\n",
    "if os.path.exists(pickle_file):\r\n",
    "    with open(pickle_file, mode='rb') as f:\r\n",
    "        y, sr = pickle.load(f)\r\n",
    "else:\r\n",
    "    y, sr = librosa.load(os.path.join(virtual_file_dir, name + '.mp3'))\r\n",
    "    with open(pickle_file, mode='wb') as f:\r\n",
    "        pickle.dump((y, sr), f)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\hobar\\anaconda3\\envs\\DeepLearningTF2\\lib\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "ys = np.array([y[i*sr*WINDOW_SIZE:(i+1)*sr*WINDOW_SIZE] for i in range(len(y)//(sr*WINDOW_SIZE))] + [y[-sr*WINDOW_SIZE:]]).reshape((-1,sr*WINDOW_SIZE,1,1))\r\n",
    "ys = tf.image.resize(ys,[WINDOW_LENGTH,1]).numpy().reshape((-1,1,WINDOW_LENGTH,1,1))\r\n",
    "ys_dataset = tf.data.Dataset.from_tensor_slices(ys)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "result_ys = []\r\n",
    "for i in tqdm(ys_dataset):\r\n",
    "    result_z = (brain.forward(i)+real_z)/2 # 向量加法中点\r\n",
    "    result_ys+=list(tf.squeeze(brain.backward(result_z).numpy()))\r\n",
    "sf.write(f'result_{name}.wav', np.array(result_ys), SAMPLING_RATE, subtype='PCM_24')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/47 [00:00<?, ?it/s]C:\\Users\\hobar\\anaconda3\\envs\\DeepLearningTF2\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:513: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "C:\\Users\\hobar\\anaconda3\\envs\\DeepLearningTF2\\lib\\site-packages\\keras\\engine\\base_layer.py:2215: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "100%|██████████| 47/47 [02:11<00:00,  2.81s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test song merge"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# test_file_dir = r'D:\\PlayGround\\research\\SongDatabase\\TestSongs'\r\n",
    "# name='virtual_align_short'\r\n",
    "# virtual_file_path = os.path.join(test_file_dir,name+'.pickle')\r\n",
    "# if os.path.exists(virtual_file_path):\r\n",
    "#     with open(virtual_file_path,mode='rb') as f:\r\n",
    "#         y = pickle.load(f)\r\n",
    "# else:\r\n",
    "#     y, sr = librosa.load(os.path.join(test_file_dir,name+'.mp3'))\r\n",
    "#     with open(virtual_file_path,mode='wb') as f:\r\n",
    "#         pickle.dump(y, f)\r\n",
    "# virtual_data = y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# name='real_short_pure_reference'\r\n",
    "# real_file_path = os.path.join(test_file_dir,name+'.pickle')\r\n",
    "# if os.path.exists(real_file_path):\r\n",
    "#     with open(real_file_path,mode='rb') as f:\r\n",
    "#         y = pickle.load(f)\r\n",
    "# else:\r\n",
    "#     y, sr = librosa.load(os.path.join(test_file_dir,name+'.mp3'))\r\n",
    "#     with open(real_file_path,mode='wb') as f:\r\n",
    "#         pickle.dump(y, f)\r\n",
    "# real_data = y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# real = np.array([real_data[i*22050*WINDOW_SIZE:(i+1)*22050*WINDOW_SIZE] for i in range(len(real_data)//(22050*WINDOW_SIZE))] + [real_data[-22050*WINDOW_SIZE:]]).reshape((-1,22050*WINDOW_SIZE,1,1))\r\n",
    "# real = tf.image.resize(real,[WINDOW_LENGTH,1]).numpy().reshape((-1,1,WINDOW_LENGTH,1,1))\r\n",
    "\r\n",
    "# virtual = np.array([virtual_data[i*22050*WINDOW_SIZE:(i+1)*22050*WINDOW_SIZE] for i in range(len(virtual_data)//(22050*WINDOW_SIZE))] + [real_data[-22050*WINDOW_SIZE:]]).reshape((-1,22050*WINDOW_SIZE,1,1))\r\n",
    "# virtual = tf.image.resize(virtual,[WINDOW_LENGTH,1]).numpy().reshape((-1,1,WINDOW_LENGTH,1,1))\r\n",
    "\r\n",
    "# ys_dataset = tf.data.Dataset.from_tensor_slices((virtual,real[:virtual.shape[0]]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# result_ys = []\r\n",
    "# for virtual,real in tqdm(ys_dataset):\r\n",
    "#     virtual_forward = brain.forward(virtual)\r\n",
    "#     real_forward = brain.forward(real)\r\n",
    "#     result_z = virtual_forward/2 + real_forward/2\r\n",
    "#     result_ys+=list(tf.clip_by_value(tf.squeeze(brain.backward(result_z)),-1,1).numpy())\r\n",
    "# virtual_file_path = os.path.join(test_file_dir,'result.wav')\r\n",
    "# sf.write(virtual_file_path, np.array(result_ys), SAMPLING_RATE, subtype='PCM_24')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6798ffb6e0df1c0d900762d231294d921ebc2c661002168db12b8cad6a55025"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('DeepLearningTF2': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}